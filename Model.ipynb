{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64454e77-164f-4b18-8d7f-e2543c47d4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Indicator Data for BHEL.csv\n",
      "\n",
      "      Open Price  High Price  Low Price  Close Price          WAP  \\\n",
      "0        2330.00     2348.00    2306.00      2344.10  2328.830845   \n",
      "1        2346.00     2352.00    2322.50      2331.05  2332.930338   \n",
      "2        2325.00     2339.50    2292.30      2306.70  2305.128109   \n",
      "3        2329.00     2330.05    2282.30      2306.95  2300.062772   \n",
      "4        2300.00     2306.70    2280.00      2290.60  2290.837787   \n",
      "...          ...         ...        ...          ...          ...   \n",
      "2473       34.35       34.50      33.60        33.80    34.071355   \n",
      "2474       33.85       35.50      33.85        35.20    34.798756   \n",
      "2475       35.55       35.70      34.35        35.35    35.008764   \n",
      "2476       36.70       36.70      35.00        35.40    35.524323   \n",
      "2477       35.20       36.50      35.20        35.90    35.928035   \n",
      "\n",
      "      No.of Shares  No. of Trades  Total Turnover (Rs.)  Deliverable Quantity  \\\n",
      "0            38184           2566            88924077.0                9147.0   \n",
      "1            54535           1577           127226356.0               31533.0   \n",
      "2            70159           1850           161725483.0               44299.0   \n",
      "3            49433           2012           113699003.0               19915.0   \n",
      "4            80234           1535           183803079.0               65820.0   \n",
      "...            ...            ...                   ...                   ...   \n",
      "2473       2231060           5430            76015237.0              806680.0   \n",
      "2474       3751556           7768           130549483.0             1867791.0   \n",
      "2475       2308296           3238            80810589.0              663550.0   \n",
      "2476       3330798           4880           118324345.0              912497.0   \n",
      "2477       5491632          10776           197303549.0             2554551.0   \n",
      "\n",
      "      % Deli. Qty to Traded Qty  ...     WMA_10       STCK       STCD  \\\n",
      "0                         23.96  ...        NaN        NaN        NaN   \n",
      "1                         57.82  ...        NaN        NaN        NaN   \n",
      "2                         63.14  ...        NaN        NaN        NaN   \n",
      "3                         40.29  ...        NaN        NaN        NaN   \n",
      "4                         82.04  ...        NaN        NaN        NaN   \n",
      "...                         ...  ...        ...        ...        ...   \n",
      "2473                      36.16  ...  34.385455  45.714286  40.952381   \n",
      "2474                      49.79  ...  34.419091  65.714286  53.095238   \n",
      "2475                      28.75  ...  34.493636  67.857143  59.761905   \n",
      "2476                      27.40  ...  34.604545  72.180451  68.583960   \n",
      "2477                      46.52  ...  34.823636  79.699248  73.245614   \n",
      "\n",
      "      Williams_R      MACD        RSI        CCI  A/D_Oscillator  Momentum  \\\n",
      "0            NaN       NaN        NaN        NaN             NaN       NaN   \n",
      "1            NaN       NaN        NaN        NaN        0.267797       NaN   \n",
      "2            NaN       NaN        NaN        NaN        0.179025       NaN   \n",
      "3            NaN       NaN        NaN        NaN        0.489005       NaN   \n",
      "4            NaN       NaN        NaN        NaN       -0.009363       NaN   \n",
      "...          ...       ...        ...        ...             ...       ...   \n",
      "2473  -54.285714  0.814615  51.779147 -34.755720        0.611111 -6.629834   \n",
      "2474  -34.285714  0.820437  58.528983  -0.047582        1.030303 -3.693570   \n",
      "2475  -32.142857  0.827614  59.188145   9.716810        0.370370 -0.980392   \n",
      "2476  -27.819549  0.827795  59.419685  40.308080        0.794118 -1.529903   \n",
      "2477  -20.300752  0.858389  61.756289  46.173626        0.846154 -2.578019   \n",
      "\n",
      "      Movement  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            1  \n",
      "4            0  \n",
      "...        ...  \n",
      "2473         0  \n",
      "2474         1  \n",
      "2475         1  \n",
      "2476         1  \n",
      "2477         1  \n",
      "\n",
      "[2478 rows x 23 columns]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Indicator Data for NIFTY BANK.csv\n",
      "\n",
      "      Index Name  Open Price  High Price  Low Price  Close Price     SMA_10  \\\n",
      "0     NIFTY BANK    11882.10    11912.15   11826.95     11855.75        NaN   \n",
      "1     NIFTY BANK    11868.40    11872.80   11545.55     11564.05        NaN   \n",
      "2     NIFTY BANK    11545.75    11545.75   11265.55     11305.45        NaN   \n",
      "3     NIFTY BANK    11350.70    11377.10   11164.75     11186.80        NaN   \n",
      "4     NIFTY BANK    11146.45    11258.50   11007.90     11053.35        NaN   \n",
      "...          ...         ...         ...        ...          ...        ...   \n",
      "2473  NIFTY BANK    30071.65    30545.85   30007.80     30402.20  30366.980   \n",
      "2474  NIFTY BANK    30558.85    30929.05   30538.15     30880.95  30394.590   \n",
      "2475  NIFTY BANK    31006.90    31359.35   31002.60     31322.50  30452.250   \n",
      "2476  NIFTY BANK    31479.80    31510.25   31007.15     31303.05  30513.450   \n",
      "2477  NIFTY BANK    31295.90    31409.50   31088.10     31264.05  30570.015   \n",
      "\n",
      "            WMA_10       STCK       STCD  Williams_R        MACD        RSI  \\\n",
      "0              NaN        NaN        NaN         NaN         NaN        NaN   \n",
      "1              NaN        NaN        NaN         NaN         NaN        NaN   \n",
      "2              NaN        NaN        NaN         NaN         NaN        NaN   \n",
      "3              NaN        NaN        NaN         NaN         NaN        NaN   \n",
      "4              NaN        NaN        NaN         NaN         NaN        NaN   \n",
      "...            ...        ...        ...         ...         ...        ...   \n",
      "2473  30212.018182  72.414844  50.483037  -27.585156  575.225038  60.082764   \n",
      "2474  30305.467273  96.736011  71.734952   -3.263989  589.697460  64.074325   \n",
      "2475  30474.178182  98.453370  89.201408   -1.546630  629.539416  67.320103   \n",
      "2476  30628.869091  91.821591  95.670324   -8.178409  652.028818  67.032810   \n",
      "2477  30765.341818  90.282218  93.519060   -9.717782  659.107080  66.420721   \n",
      "\n",
      "             CCI  A/D_Oscillator  Momentum  Movement  \n",
      "0            NaN             NaN       NaN         0  \n",
      "1            NaN        0.052101       NaN         0  \n",
      "2            NaN       -0.065310       NaN         0  \n",
      "3            NaN        0.337415       NaN         0  \n",
      "4            NaN        0.286113       NaN         0  \n",
      "...          ...             ...       ...       ...  \n",
      "2473   28.667441        1.231391  0.463619         1  \n",
      "2474   89.770534        1.347787  0.558624         1  \n",
      "2475  141.911503        1.340995  2.661884         1  \n",
      "2476  133.807874        0.373186  2.281338         0  \n",
      "2477  122.244099        0.331207  1.685265         0  \n",
      "\n",
      "[2478 rows x 16 columns]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Indicator Data for Sensex.csv\n",
      "\n",
      "      Open Price  High Price  Low Price  Close Price     SMA_10        WMA_10  \\\n",
      "0       20621.61    20664.80   20531.00     20561.05        NaN           NaN   \n",
      "1       20617.38    20651.21   20449.01     20498.72        NaN           NaN   \n",
      "2       20509.95    20509.95   20243.95     20301.10        NaN           NaN   \n",
      "3       20395.50    20425.85   20107.17     20184.74        NaN           NaN   \n",
      "4       20163.85    20210.62   19629.22     19691.81        NaN           NaN   \n",
      "...          ...         ...        ...          ...        ...           ...   \n",
      "2473    46743.49    47053.40   46539.02     46973.54  46411.150  46453.479636   \n",
      "2474    47153.59    47406.72   47148.24     47353.75  46536.624  46624.861455   \n",
      "2475    47466.62    47714.55   47361.90     47613.08  46672.586  46820.580727   \n",
      "2476    47789.03    47807.85   47358.36     47746.22  46820.891  47015.786909   \n",
      "2477    47753.11    47896.97   47602.12     47751.33  46929.378  47184.957636   \n",
      "\n",
      "           STCK       STCD  Williams_R         MACD        RSI         CCI  \\\n",
      "0           NaN        NaN         NaN          NaN        NaN         NaN   \n",
      "1           NaN        NaN         NaN          NaN        NaN         NaN   \n",
      "2           NaN        NaN         NaN          NaN        NaN         NaN   \n",
      "3           NaN        NaN         NaN          NaN        NaN         NaN   \n",
      "4           NaN        NaN         NaN          NaN        NaN         NaN   \n",
      "...         ...        ...         ...          ...        ...         ...   \n",
      "2473  96.147913  76.223637   -3.852087   912.978559  68.303503  107.381353   \n",
      "2474  97.867243  89.475536   -2.132757   939.156837  70.606806  139.947645   \n",
      "2475  96.364998  96.793385   -3.635002   969.651535  72.096223  153.284385   \n",
      "2476  97.863608  97.365283   -2.136392   993.114087  72.856678  145.305541   \n",
      "2477  95.102711  96.443772   -4.897289  1000.586524  72.887219  138.280074   \n",
      "\n",
      "      A/D_Oscillator  Momentum  Movement  \n",
      "0                NaN       NaN         0  \n",
      "1           0.445895       NaN         0  \n",
      "2           0.042218       NaN         0  \n",
      "3           0.391459       NaN         0  \n",
      "4           0.044513       NaN         0  \n",
      "...              ...       ...       ...  \n",
      "2473        1.184377  2.992928         1  \n",
      "2474        1.675874  2.711833         1  \n",
      "2475        1.023111  3.597050         1  \n",
      "2476        0.433313  3.573200         1  \n",
      "2477        0.511277  3.238396         1  \n",
      "\n",
      "[2478 rows x 15 columns]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Indicator Data for TATA.csv\n",
      "\n",
      "      Open Price  High Price  Low Price  Close Price          WAP  \\\n",
      "0        1321.00     1334.30    1302.85      1306.45  1315.686655   \n",
      "1        1312.00     1321.00    1287.00      1300.50  1304.699153   \n",
      "2        1297.00     1310.00    1275.15      1282.40  1290.576266   \n",
      "3        1287.55     1301.00    1250.00      1259.05  1273.589956   \n",
      "4        1258.00     1263.95    1177.70      1189.50  1215.648474   \n",
      "...          ...         ...        ...          ...          ...   \n",
      "2473      171.50      177.90     171.50       175.90   175.550197   \n",
      "2474      180.00      187.45     179.00       186.30   184.338630   \n",
      "2475      188.00      188.60     181.05       183.40   184.929195   \n",
      "2476      183.30      185.30     180.45       184.00   182.543717   \n",
      "2477      185.00      187.50     182.85       183.70   185.438838   \n",
      "\n",
      "      No.of Shares  No. of Trades  Total Turnover (Rs.)  Deliverable Quantity  \\\n",
      "0           325140          10149           427782359.0               75311.0   \n",
      "1           543153          12907           708651259.0              183357.0   \n",
      "2           266998           9490           344581282.0               28704.0   \n",
      "3           355601          10298           452889862.0               60800.0   \n",
      "4           796091          20820           967766809.0              220905.0   \n",
      "...            ...            ...                   ...                   ...   \n",
      "2473       5228776          30286           917912656.0             1559342.0   \n",
      "2474       4106762          20858           757034881.0              767600.0   \n",
      "2475       3312073          15460           612498993.0              490692.0   \n",
      "2476       1478809           8553           269947292.0              155635.0   \n",
      "2477       2122018          10651           393504553.0              331046.0   \n",
      "\n",
      "      % Deli. Qty to Traded Qty  ...      WMA_10       STCK       STCD  \\\n",
      "0                         23.16  ...         NaN        NaN        NaN   \n",
      "1                         33.76  ...         NaN        NaN        NaN   \n",
      "2                         10.75  ...         NaN        NaN        NaN   \n",
      "3                         17.10  ...         NaN        NaN        NaN   \n",
      "4                         27.75  ...         NaN        NaN        NaN   \n",
      "...                         ...  ...         ...        ...        ...   \n",
      "2473                      29.82  ...  173.558182  64.715719  43.466316   \n",
      "2474                      18.69  ...  175.530000  96.278317  66.759917   \n",
      "2475                      14.82  ...  176.838182  83.775351  81.589796   \n",
      "2476                      10.52  ...  178.150000  85.647426  88.567031   \n",
      "2477                      15.60  ...  179.312727  84.711388  84.711388   \n",
      "\n",
      "      Williams_R      MACD        RSI        CCI  A/D_Oscillator  Momentum  \\\n",
      "0            NaN       NaN        NaN        NaN             NaN       NaN   \n",
      "1            NaN       NaN        NaN        NaN        0.427941       NaN   \n",
      "2            NaN       NaN        NaN        NaN        0.272597       NaN   \n",
      "3            NaN       NaN        NaN        NaN        0.364706       NaN   \n",
      "4            NaN       NaN        NaN        NaN        0.056812       NaN   \n",
      "...          ...       ...        ...        ...             ...       ...   \n",
      "2473  -35.284281  3.097334  55.412886 -48.349014        1.359375 -3.218707   \n",
      "2474   -3.721683  3.806775  63.831210  79.825358        1.366864  1.970443   \n",
      "2475  -16.224649  4.087884  60.406310  74.366783        0.304636  3.265766   \n",
      "2476  -14.352574  4.309404  60.874064  54.926921        0.391753  2.908277   \n",
      "2477  -15.288612  4.409918  60.489273  74.286317        0.752688  3.434685   \n",
      "\n",
      "      Movement  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "...        ...  \n",
      "2473         1  \n",
      "2474         1  \n",
      "2475         0  \n",
      "2476         1  \n",
      "2477         0  \n",
      "\n",
      "[2478 rows x 23 columns]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ta\n",
    "\n",
    "# Function to generate technical indicators for a list of datasets\n",
    "def generate_indicator_data(datasets):\n",
    "    indicator_data = []\n",
    "\n",
    "    for dataset in datasets:\n",
    "        # Read the dataset\n",
    "        stock_data = pd.read_csv(dataset)\n",
    "        stock_data = stock_data.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "        # Apply indicator calculations\n",
    "        stock_data = calculate_moving_averages(stock_data)\n",
    "        stock_data = calculate_stochastic_oscillators(stock_data)\n",
    "        stock_data = calculate_macd(stock_data)\n",
    "        stock_data = calculate_rsi(stock_data)\n",
    "        stock_data = calculate_cci(stock_data)\n",
    "        stock_data = calculate_ad_oscillator(stock_data)\n",
    "        stock_data = calculate_momentum(stock_data)\n",
    "\n",
    "        # Calculate daily price change\n",
    "        stock_data['Price Change'] = stock_data['Close Price'].diff()\n",
    "\n",
    "        # Define movement criterion\n",
    "        stock_data['Movement'] = 0  # Initialize movement column\n",
    "        stock_data.loc[stock_data['Price Change'] > 0, 'Movement'] = 1\n",
    "\n",
    "        # Drop rows with NaN values in the 'Movement' column\n",
    "        stock_data.dropna(subset=['Movement'], inplace=True)\n",
    "\n",
    "        # Exclude 'Date', 'Price Change', and 'Movement' columns from indicator data\n",
    "        indicator_data.append(stock_data.drop(columns=['Date', 'Price Change']))\n",
    "\n",
    "    return indicator_data\n",
    "\n",
    "# Function to calculate moving averages (SMA and WMA)\n",
    "def calculate_moving_averages(stock_data):\n",
    "    stock_data['SMA_10'] = ta.trend.sma_indicator(stock_data['Close Price'], window=10)\n",
    "    stock_data['WMA_10'] = ta.trend.wma_indicator(stock_data['Close Price'], window=10)\n",
    "    return stock_data\n",
    "\n",
    "# Function to calculate stochastic oscillators (STCK%, STCD%, Williams R%)\n",
    "def calculate_stochastic_oscillators(stock_data):\n",
    "    stock_data['STCK'] = ta.momentum.stoch(stock_data['High Price'], stock_data['Low Price'], stock_data['Close Price'], window=14)\n",
    "    stock_data['STCD'] = ta.momentum.stoch_signal(stock_data['High Price'], stock_data['Low Price'], stock_data['Close Price'], window=14)\n",
    "    stock_data['Williams_R'] = ta.momentum.williams_r(stock_data['High Price'], stock_data['Low Price'], stock_data['Close Price'], lbp=14)\n",
    "    return stock_data\n",
    "\n",
    "# Function to calculate MACD\n",
    "def calculate_macd(stock_data):\n",
    "    stock_data['MACD'] = ta.trend.macd(stock_data['Close Price'])\n",
    "    return stock_data\n",
    "\n",
    "# Function to calculate RSI\n",
    "def calculate_rsi(stock_data):\n",
    "    stock_data['RSI'] = ta.momentum.rsi(stock_data['Close Price'])\n",
    "    return stock_data\n",
    "\n",
    "# Function to calculate CCI\n",
    "def calculate_cci(stock_data):\n",
    "    stock_data['CCI'] = ta.trend.cci(stock_data['High Price'], stock_data['Low Price'], stock_data['Close Price'])\n",
    "    return stock_data\n",
    "\n",
    "# Function to calculate A/D oscillator\n",
    "def calculate_ad_oscillator(stock_data):\n",
    "    # Calculate A/D oscillator using the provided formula\n",
    "    stock_data['A/D_Oscillator'] = (stock_data['High Price'] - stock_data['Close Price'].shift(1)) / (stock_data['High Price'] - stock_data['Low Price'])\n",
    "    return stock_data\n",
    "\n",
    "# Function to calculate momentum\n",
    "def calculate_momentum(stock_data):\n",
    "    stock_data['Momentum'] = ta.momentum.roc(stock_data['Close Price'])\n",
    "    return stock_data\n",
    "\n",
    "\n",
    "# Example usage\n",
    "datasets = ['BHEL.csv', 'NIFTY BANK.csv', 'Sensex.csv', 'TATA.csv']\n",
    "indicator_data = generate_indicator_data(datasets)\n",
    "\n",
    "# Print each processed DataFrame\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    print(f\"\\n# Indicator Data for {dataset}\\n\")\n",
    "    print(indicator_data[idx])\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9ad0810-f920-4c3a-b5c0-f79f6e6cc30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Trend Data for BHEL.csv\n",
      "\n",
      "      Open Price  High Price  Low Price  Close Price          WAP  \\\n",
      "0        2330.00     2348.00    2306.00      2344.10  2328.830845   \n",
      "1        2346.00     2352.00    2322.50      2331.05  2332.930338   \n",
      "2        2325.00     2339.50    2292.30      2306.70  2305.128109   \n",
      "3        2329.00     2330.05    2282.30      2306.95  2300.062772   \n",
      "4        2300.00     2306.70    2280.00      2290.60  2290.837787   \n",
      "...          ...         ...        ...          ...          ...   \n",
      "2473       34.35       34.50      33.60        33.80    34.071355   \n",
      "2474       33.85       35.50      33.85        35.20    34.798756   \n",
      "2475       35.55       35.70      34.35        35.35    35.008764   \n",
      "2476       36.70       36.70      35.00        35.40    35.524323   \n",
      "2477       35.20       36.50      35.20        35.90    35.928035   \n",
      "\n",
      "      No.of Shares  No. of Trades  Total Turnover (Rs.)  Deliverable Quantity  \\\n",
      "0            38184           2566            88924077.0                9147.0   \n",
      "1            54535           1577           127226356.0               31533.0   \n",
      "2            70159           1850           161725483.0               44299.0   \n",
      "3            49433           2012           113699003.0               19915.0   \n",
      "4            80234           1535           183803079.0               65820.0   \n",
      "...            ...            ...                   ...                   ...   \n",
      "2473       2231060           5430            76015237.0              806680.0   \n",
      "2474       3751556           7768           130549483.0             1867791.0   \n",
      "2475       2308296           3238            80810589.0              663550.0   \n",
      "2476       3330798           4880           118324345.0              912497.0   \n",
      "2477       5491632          10776           197303549.0             2554551.0   \n",
      "\n",
      "      % Deli. Qty to Traded Qty  ...  SMA_10_trend  WMA_10_trend  STCK_trend  \\\n",
      "0                         23.96  ...            -1            -1           0   \n",
      "1                         57.82  ...            -1            -1           0   \n",
      "2                         63.14  ...            -1            -1           0   \n",
      "3                         40.29  ...            -1            -1           0   \n",
      "4                         82.04  ...            -1            -1           0   \n",
      "...                         ...  ...           ...           ...         ...   \n",
      "2473                      36.16  ...            -1            -1          -1   \n",
      "2474                      49.79  ...             1             1           1   \n",
      "2475                      28.75  ...             1             1           1   \n",
      "2476                      27.40  ...             1             1           1   \n",
      "2477                      46.52  ...             1             1           1   \n",
      "\n",
      "      STCD_trend  Williams_R_trend  MACD_trend  RSI_trend  CCI_trend  \\\n",
      "0              0                 0           0          0          0   \n",
      "1              0                 0           0          0          0   \n",
      "2              0                 0           0          0          0   \n",
      "3              0                 0           0          0          0   \n",
      "4              0                 0           0          0          0   \n",
      "...          ...               ...         ...        ...        ...   \n",
      "2473           1                -1          -1         -1          1   \n",
      "2474           1                 1           1          1          1   \n",
      "2475           1                 1           1          1          1   \n",
      "2476           1                 1           1          1          1   \n",
      "2477           1                 1           1          1          1   \n",
      "\n",
      "      A/D_Oscillator_trend  Momentum_trend  \n",
      "0                        0               0  \n",
      "1                        0               0  \n",
      "2                       -1               0  \n",
      "3                        1               0  \n",
      "4                       -1               0  \n",
      "...                    ...             ...  \n",
      "2473                    -1              -1  \n",
      "2474                     1              -1  \n",
      "2475                    -1              -1  \n",
      "2476                     1              -1  \n",
      "2477                     1              -1  \n",
      "\n",
      "[2478 rows x 40 columns]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Trend Data for NIFTY BANK.csv\n",
      "\n",
      "      Index Name  Open Price  High Price  Low Price  Close Price     SMA_10  \\\n",
      "0     NIFTY BANK    11882.10    11912.15   11826.95     11855.75        NaN   \n",
      "1     NIFTY BANK    11868.40    11872.80   11545.55     11564.05        NaN   \n",
      "2     NIFTY BANK    11545.75    11545.75   11265.55     11305.45        NaN   \n",
      "3     NIFTY BANK    11350.70    11377.10   11164.75     11186.80        NaN   \n",
      "4     NIFTY BANK    11146.45    11258.50   11007.90     11053.35        NaN   \n",
      "...          ...         ...         ...        ...          ...        ...   \n",
      "2473  NIFTY BANK    30071.65    30545.85   30007.80     30402.20  30366.980   \n",
      "2474  NIFTY BANK    30558.85    30929.05   30538.15     30880.95  30394.590   \n",
      "2475  NIFTY BANK    31006.90    31359.35   31002.60     31322.50  30452.250   \n",
      "2476  NIFTY BANK    31479.80    31510.25   31007.15     31303.05  30513.450   \n",
      "2477  NIFTY BANK    31295.90    31409.50   31088.10     31264.05  30570.015   \n",
      "\n",
      "            WMA_10       STCK       STCD  Williams_R  ...  SMA_10_trend  \\\n",
      "0              NaN        NaN        NaN         NaN  ...            -1   \n",
      "1              NaN        NaN        NaN         NaN  ...            -1   \n",
      "2              NaN        NaN        NaN         NaN  ...            -1   \n",
      "3              NaN        NaN        NaN         NaN  ...            -1   \n",
      "4              NaN        NaN        NaN         NaN  ...            -1   \n",
      "...            ...        ...        ...         ...  ...           ...   \n",
      "2473  30212.018182  72.414844  50.483037  -27.585156  ...             1   \n",
      "2474  30305.467273  96.736011  71.734952   -3.263989  ...             1   \n",
      "2475  30474.178182  98.453370  89.201408   -1.546630  ...             1   \n",
      "2476  30628.869091  91.821591  95.670324   -8.178409  ...             1   \n",
      "2477  30765.341818  90.282218  93.519060   -9.717782  ...             1   \n",
      "\n",
      "      WMA_10_trend  STCK_trend  STCD_trend  Williams_R_trend  MACD_trend  \\\n",
      "0               -1           0           0                 0           0   \n",
      "1               -1           0           0                 0           0   \n",
      "2               -1           0           0                 0           0   \n",
      "3               -1           0           0                 0           0   \n",
      "4               -1           0           0                 0           0   \n",
      "...            ...         ...         ...               ...         ...   \n",
      "2473             1           1           1                 1          -1   \n",
      "2474             1           1           1                 1           1   \n",
      "2475             1           1           1                 1           1   \n",
      "2476             1          -1           1                -1           1   \n",
      "2477             1          -1          -1                -1           1   \n",
      "\n",
      "      RSI_trend  CCI_trend  A/D_Oscillator_trend  Momentum_trend  \n",
      "0             0          0                     0               0  \n",
      "1             0          0                     0               0  \n",
      "2             0          0                    -1               0  \n",
      "3             0          0                     1               0  \n",
      "4             0          0                    -1               0  \n",
      "...         ...        ...                   ...             ...  \n",
      "2473          1          1                     1               1  \n",
      "2474          1          1                     1               1  \n",
      "2475          1          1                    -1               1  \n",
      "2476         -1         -1                    -1               1  \n",
      "2477         -1         -1                    -1               1  \n",
      "\n",
      "[2478 rows x 33 columns]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Trend Data for Sensex.csv\n",
      "\n",
      "      Open Price  High Price  Low Price  Close Price     SMA_10        WMA_10  \\\n",
      "0       20621.61    20664.80   20531.00     20561.05        NaN           NaN   \n",
      "1       20617.38    20651.21   20449.01     20498.72        NaN           NaN   \n",
      "2       20509.95    20509.95   20243.95     20301.10        NaN           NaN   \n",
      "3       20395.50    20425.85   20107.17     20184.74        NaN           NaN   \n",
      "4       20163.85    20210.62   19629.22     19691.81        NaN           NaN   \n",
      "...          ...         ...        ...          ...        ...           ...   \n",
      "2473    46743.49    47053.40   46539.02     46973.54  46411.150  46453.479636   \n",
      "2474    47153.59    47406.72   47148.24     47353.75  46536.624  46624.861455   \n",
      "2475    47466.62    47714.55   47361.90     47613.08  46672.586  46820.580727   \n",
      "2476    47789.03    47807.85   47358.36     47746.22  46820.891  47015.786909   \n",
      "2477    47753.11    47896.97   47602.12     47751.33  46929.378  47184.957636   \n",
      "\n",
      "           STCK       STCD  Williams_R         MACD  ...  SMA_10_trend  \\\n",
      "0           NaN        NaN         NaN          NaN  ...            -1   \n",
      "1           NaN        NaN         NaN          NaN  ...            -1   \n",
      "2           NaN        NaN         NaN          NaN  ...            -1   \n",
      "3           NaN        NaN         NaN          NaN  ...            -1   \n",
      "4           NaN        NaN         NaN          NaN  ...            -1   \n",
      "...         ...        ...         ...          ...  ...           ...   \n",
      "2473  96.147913  76.223637   -3.852087   912.978559  ...             1   \n",
      "2474  97.867243  89.475536   -2.132757   939.156837  ...             1   \n",
      "2475  96.364998  96.793385   -3.635002   969.651535  ...             1   \n",
      "2476  97.863608  97.365283   -2.136392   993.114087  ...             1   \n",
      "2477  95.102711  96.443772   -4.897289  1000.586524  ...             1   \n",
      "\n",
      "      WMA_10_trend  STCK_trend  STCD_trend  Williams_R_trend  MACD_trend  \\\n",
      "0               -1           0           0                 0           0   \n",
      "1               -1           0           0                 0           0   \n",
      "2               -1           0           0                 0           0   \n",
      "3               -1           0           0                 0           0   \n",
      "4               -1           0           0                 0           0   \n",
      "...            ...         ...         ...               ...         ...   \n",
      "2473             1           1           1                 1           1   \n",
      "2474             1           1           1                 1           1   \n",
      "2475             1          -1           1                -1           1   \n",
      "2476             1           1           1                 1           1   \n",
      "2477             1          -1          -1                -1           1   \n",
      "\n",
      "      RSI_trend  CCI_trend  A/D_Oscillator_trend  Momentum_trend  \n",
      "0             0          0                     0               0  \n",
      "1             0          0                     0               0  \n",
      "2             0          0                    -1               0  \n",
      "3             0          0                     1               0  \n",
      "4             0          0                    -1               0  \n",
      "...         ...        ...                   ...             ...  \n",
      "2473          1          1                     1               1  \n",
      "2474         -1          1                     1               1  \n",
      "2475         -1          1                    -1               1  \n",
      "2476         -1         -1                    -1               1  \n",
      "2477         -1         -1                     1               1  \n",
      "\n",
      "[2478 rows x 32 columns]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Trend Data for TATA.csv\n",
      "\n",
      "      Open Price  High Price  Low Price  Close Price          WAP  \\\n",
      "0        1321.00     1334.30    1302.85      1306.45  1315.686655   \n",
      "1        1312.00     1321.00    1287.00      1300.50  1304.699153   \n",
      "2        1297.00     1310.00    1275.15      1282.40  1290.576266   \n",
      "3        1287.55     1301.00    1250.00      1259.05  1273.589956   \n",
      "4        1258.00     1263.95    1177.70      1189.50  1215.648474   \n",
      "...          ...         ...        ...          ...          ...   \n",
      "2473      171.50      177.90     171.50       175.90   175.550197   \n",
      "2474      180.00      187.45     179.00       186.30   184.338630   \n",
      "2475      188.00      188.60     181.05       183.40   184.929195   \n",
      "2476      183.30      185.30     180.45       184.00   182.543717   \n",
      "2477      185.00      187.50     182.85       183.70   185.438838   \n",
      "\n",
      "      No.of Shares  No. of Trades  Total Turnover (Rs.)  Deliverable Quantity  \\\n",
      "0           325140          10149           427782359.0               75311.0   \n",
      "1           543153          12907           708651259.0              183357.0   \n",
      "2           266998           9490           344581282.0               28704.0   \n",
      "3           355601          10298           452889862.0               60800.0   \n",
      "4           796091          20820           967766809.0              220905.0   \n",
      "...            ...            ...                   ...                   ...   \n",
      "2473       5228776          30286           917912656.0             1559342.0   \n",
      "2474       4106762          20858           757034881.0              767600.0   \n",
      "2475       3312073          15460           612498993.0              490692.0   \n",
      "2476       1478809           8553           269947292.0              155635.0   \n",
      "2477       2122018          10651           393504553.0              331046.0   \n",
      "\n",
      "      % Deli. Qty to Traded Qty  ...  SMA_10_trend  WMA_10_trend  STCK_trend  \\\n",
      "0                         23.16  ...            -1            -1           0   \n",
      "1                         33.76  ...            -1            -1           0   \n",
      "2                         10.75  ...            -1            -1           0   \n",
      "3                         17.10  ...            -1            -1           0   \n",
      "4                         27.75  ...            -1            -1           0   \n",
      "...                         ...  ...           ...           ...         ...   \n",
      "2473                      29.82  ...             1             1           1   \n",
      "2474                      18.69  ...             1             1           1   \n",
      "2475                      14.82  ...             1             1          -1   \n",
      "2476                      10.52  ...             1             1           1   \n",
      "2477                      15.60  ...             1             1          -1   \n",
      "\n",
      "      STCD_trend  Williams_R_trend  MACD_trend  RSI_trend  CCI_trend  \\\n",
      "0              0                 0           0          0          0   \n",
      "1              0                 0           0          0          0   \n",
      "2              0                 0           0          0          0   \n",
      "3              0                 0           0          0          0   \n",
      "4              0                 0           0          0          0   \n",
      "...          ...               ...         ...        ...        ...   \n",
      "2473           1                 1          -1          1          1   \n",
      "2474           1                 1           1          1          1   \n",
      "2475           1                -1           1         -1         -1   \n",
      "2476           1                 1           1          1         -1   \n",
      "2477          -1                -1           1         -1          1   \n",
      "\n",
      "      A/D_Oscillator_trend  Momentum_trend  \n",
      "0                        0               0  \n",
      "1                        0               0  \n",
      "2                       -1               0  \n",
      "3                        1               0  \n",
      "4                       -1               0  \n",
      "...                    ...             ...  \n",
      "2473                     1              -1  \n",
      "2474                     1               1  \n",
      "2475                    -1               1  \n",
      "2476                     1               1  \n",
      "2477                     1               1  \n",
      "\n",
      "[2478 rows x 40 columns]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to convert technical indicators to trend deterministic discrete data\n",
    "def convert_to_trend_data(indicator_data):\n",
    "    # Create lagged columns for each technical indicator\n",
    "    for indicator in ['STCK', 'STCD', 'Williams_R', 'MACD', 'RSI', 'CCI', 'A/D_Oscillator']:\n",
    "        indicator_data[indicator + '_lag'] = indicator_data[indicator].shift(1)\n",
    "\n",
    "    # Define the conversion function\n",
    "    def convert_to_trend(row):\n",
    "        converted_data = []\n",
    "\n",
    "        # Moving Averages (SMA_10 and WMA_10)\n",
    "        if row['Close Price'] > row['SMA_10']:\n",
    "            converted_data.append(1)\n",
    "        else:\n",
    "            converted_data.append(-1)\n",
    "\n",
    "        if row['Close Price'] > row['WMA_10']:\n",
    "            converted_data.append(1)\n",
    "        else:\n",
    "            converted_data.append(-1)\n",
    "\n",
    "        # Stochastic Oscillators (STCK, STCD, and Williams_R)\n",
    "        for indicator in ['STCK', 'STCD', 'Williams_R']:\n",
    "            if not pd.isnull(row[indicator]) and not pd.isnull(row[indicator + '_lag']):\n",
    "                if row[indicator] > row[indicator + '_lag']:\n",
    "                    converted_data.append(1)\n",
    "                else:\n",
    "                    converted_data.append(-1)\n",
    "            else:\n",
    "                converted_data.append(0)  # Handle missing values by assigning 0\n",
    "\n",
    "        # MACD\n",
    "        if not pd.isnull(row['MACD']) and not pd.isnull(row['MACD_lag']):\n",
    "            if row['MACD'] > row['MACD_lag']:\n",
    "                converted_data.append(1)\n",
    "            else:\n",
    "                converted_data.append(-1)\n",
    "        else:\n",
    "            converted_data.append(0)\n",
    "\n",
    "        # RSI (Relative Strength Index)\n",
    "        if not pd.isnull(row['RSI']):\n",
    "            if row['RSI'] > 70:\n",
    "                converted_data.append(-1)\n",
    "            elif row['RSI'] < 30:\n",
    "                converted_data.append(1)\n",
    "            else:\n",
    "                if not pd.isnull(row['RSI_lag']):\n",
    "                    if row['RSI'] > row['RSI_lag']:\n",
    "                        converted_data.append(1)\n",
    "                    else:\n",
    "                        converted_data.append(-1)\n",
    "                else:\n",
    "                    converted_data.append(0)\n",
    "        else:\n",
    "            converted_data.append(0)\n",
    "\n",
    "        # CCI (Commodity Channel Index)\n",
    "        if not pd.isnull(row['CCI']) and not pd.isnull(row['CCI_lag']):\n",
    "            if row['CCI'] > row['CCI_lag']:\n",
    "                converted_data.append(1)\n",
    "            else:\n",
    "                converted_data.append(-1)\n",
    "        else:\n",
    "            converted_data.append(0)\n",
    "\n",
    "        # A/D Oscillator\n",
    "        if not pd.isnull(row['A/D_Oscillator']) and not pd.isnull(row['A/D_Oscillator_lag']):\n",
    "            if row['A/D_Oscillator'] > row['A/D_Oscillator_lag']:\n",
    "                converted_data.append(1)\n",
    "            else:\n",
    "                converted_data.append(-1)\n",
    "        else:\n",
    "            converted_data.append(0)\n",
    "\n",
    "        # Momentum\n",
    "        if not pd.isnull(row['Momentum']):\n",
    "            if row['Momentum'] > 0:\n",
    "                converted_data.append(1)\n",
    "            else:\n",
    "                converted_data.append(-1)\n",
    "        else:\n",
    "            converted_data.append(0)\n",
    "\n",
    "        return converted_data\n",
    "\n",
    "    # Apply the function to the DataFrame\n",
    "    trend_data = indicator_data.apply(convert_to_trend, axis=1)\n",
    "\n",
    "    # Define column names for trend data\n",
    "    indicator_columns = ['SMA_10', 'WMA_10', 'STCK', 'STCD', 'Williams_R', 'MACD', 'RSI', 'CCI', 'A/D_Oscillator', 'Momentum']\n",
    "    trend_columns = [f\"{indicator}_trend\" for indicator in indicator_columns]\n",
    "\n",
    "    # Convert the trend data into a DataFrame with appropriate column names\n",
    "    trend_data_df = pd.DataFrame(trend_data.values.tolist(), columns=trend_columns)\n",
    "\n",
    "    # Concatenate the trend data DataFrame with the original stock data\n",
    "    final_data = pd.concat([indicator_data, trend_data_df], axis=1)\n",
    "\n",
    "    return final_data\n",
    "\n",
    "# Loop through indicator data and generate trend data for each dataset\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    trend_data = convert_to_trend_data(indicator_data[idx])\n",
    "    print(f\"\\n# Trend Data for {dataset}\\n\")\n",
    "    print(trend_data)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5baae-aa71-4817-8241-f05c3dec8856",
   "metadata": {},
   "source": [
    "# SVM for continous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b94b854-02d5-4fd1-8472-f2b4781f1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "034c6c9a-dcc8-44f4-bcfe-a3b27841bc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BHEL:\n",
      "Polynomial Kernel:\n",
      "Best parameters: {'C': 100, 'degree': 1, 'kernel': 'poly'}\n",
      "Best accuracy: 0.9702261913848815\n",
      "Radial Basis Kernel:\n",
      "Best parameters: {'C': 5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Best accuracy: 0.8572157341678752\n",
      "Overall accuracy: 0.9137209627763784\n",
      "Results for NIFTY BANK:\n",
      "Polynomial Kernel:\n",
      "Best parameters: {'C': 100, 'degree': 1, 'kernel': 'poly'}\n",
      "Best accuracy: 0.97476655726026\n",
      "Radial Basis Kernel:\n",
      "Best parameters: {'C': 0.5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Best accuracy: 0.8849578912551206\n",
      "Overall accuracy: 0.9298622242576903\n",
      "Results for S&P BSE Sensex:\n",
      "Polynomial Kernel:\n",
      "Best parameters: {'C': 100, 'degree': 1, 'kernel': 'poly'}\n",
      "Best accuracy: 0.9778032211281582\n",
      "Radial Basis Kernel:\n",
      "Best parameters: {'C': 5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Best accuracy: 0.8940424395084344\n",
      "Overall accuracy: 0.9359228303182963\n",
      "Results for TATA:\n",
      "Polynomial Kernel:\n",
      "Best parameters: {'C': 100, 'degree': 1, 'kernel': 'poly'}\n",
      "Best accuracy: 0.9687224893774014\n",
      "Radial Basis Kernel:\n",
      "Best parameters: {'C': 5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Best accuracy: 0.8758936976821108\n",
      "Overall accuracy: 0.9223080935297561\n",
      "\n",
      "Accuracy:\n",
      "BHEL: 0.9137209627763784\n",
      "NIFTY BANK: 0.9298622242576903\n",
      "S&P BSE Sensex: 0.9359228303182963\n",
      "TATA: 0.9223080935297561\n",
      "\n",
      "Overall accuracy: 0.9254535277205302\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define dataset names\n",
    "dataset_names = [\"BHEL\", \"NIFTY BANK\", \"S&P BSE Sensex\", \"TATA\"]\n",
    "\n",
    "# Define the parameters grid for SVM\n",
    "param_grid_poly = {\n",
    "    'kernel': ['poly'],\n",
    "    'degree': [1, 2, 3, 4],\n",
    "    'C': [0.5, 1, 5, 10, 100]\n",
    "}\n",
    "\n",
    "param_grid_rbf = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 10.0],\n",
    "    'C': [0.5, 1, 5, 10]\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for idx, (dataset, dataset_name) in enumerate(zip(indicator_data, dataset_names)):\n",
    "    numeric_columns = dataset.drop(['Close Price', 'Movement'], axis=1).select_dtypes(include=np.number).columns\n",
    "    X = dataset[numeric_columns]\n",
    "    y = dataset['Movement']\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_filled = imputer.fit_transform(X)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define the SVM model\n",
    "    svm_model = SVC()\n",
    "\n",
    "    # Perform grid search for polynomial kernel\n",
    "    grid_search_poly = GridSearchCV(estimator=svm_model, param_grid=param_grid_poly, cv=5, scoring='accuracy')\n",
    "    grid_search_poly.fit(X_train_scaled, y_train)\n",
    "    best_model_poly = grid_search_poly.best_estimator_\n",
    "    \n",
    "    # Perform grid search for radial basis kernel\n",
    "    grid_search_rbf = GridSearchCV(estimator=svm_model, param_grid=param_grid_rbf, cv=5, scoring='accuracy')\n",
    "    grid_search_rbf.fit(X_train_scaled, y_train)\n",
    "    best_model_rbf = grid_search_rbf.best_estimator_\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'dataset_name': dataset_name,\n",
    "        'best_model_poly': best_model_poly,\n",
    "        'best_params_poly': grid_search_poly.best_params_,\n",
    "        'accuracy_poly': grid_search_poly.best_score_,\n",
    "        'best_model_rbf': best_model_rbf,\n",
    "        'best_params_rbf': grid_search_rbf.best_params_,\n",
    "        'accuracy_rbf': grid_search_rbf.best_score_,\n",
    "    })\n",
    "\n",
    "# Store overall accuracies\n",
    "overall_accuracies = []\n",
    "\n",
    "# Print results for each dataset\n",
    "for result in results:\n",
    "    dataset_name = result['dataset_name']\n",
    "    \n",
    "    print(f\"Results for {dataset_name}:\")\n",
    "    print(\"Polynomial Kernel:\")\n",
    "    print(f\"Best parameters: {result['best_params_poly']}\")\n",
    "    print(f\"Best accuracy: {result['accuracy_poly']}\")\n",
    "    print(\"Radial Basis Kernel:\")\n",
    "    print(f\"Best parameters: {result['best_params_rbf']}\")\n",
    "    print(f\"Best accuracy: {result['accuracy_rbf']}\")\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = (result['accuracy_poly'] + result['accuracy_rbf']) / 2\n",
    "    print(f\"Overall accuracy: {overall_accuracy}\")\n",
    "    \n",
    "    # Append overall accuracy to the list\n",
    "    overall_accuracies.append(overall_accuracy)\n",
    "\n",
    "# Print overall accuracies\n",
    "print(\"\\nAccuracy:\")\n",
    "for result in results:\n",
    "    dataset_name = result['dataset_name']\n",
    "    overall_accuracy = (result['accuracy_poly'] + result['accuracy_rbf']) / 2\n",
    "    print(f\"{dataset_name}: {overall_accuracy}\")\n",
    "\n",
    "# Calculate the mean of overall accuracies\n",
    "ovacc_svm_cont = np.mean(overall_accuracies)\n",
    "\n",
    "# Print overall accuracy mean\n",
    "print(\"\\nOverall accuracy:\", ovacc_svm_cont)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b1b50f-1c00-4930-aa20-1b172cbecdf9",
   "metadata": {},
   "source": [
    "# SVM for trend deterministic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9ea070f-378b-482c-a022-ec3136ff0644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BHEL:\n",
      "Polynomial Kernel:\n",
      "Best parameters: {'C': 100, 'degree': 1, 'kernel': 'poly'}\n",
      "Best accuracy: 0.9888965218940029\n",
      "Radial Basis Kernel:\n",
      "Best parameters: {'C': 5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Best accuracy: 0.9253288553036663\n",
      "Overall accuracy: 0.9571126885988346\n",
      "Results for NIFTY BANK:\n",
      "Polynomial Kernel:\n",
      "Best parameters: {'C': 100, 'degree': 1, 'kernel': 'poly'}\n",
      "Best accuracy: 0.9939457547769889\n",
      "Radial Basis Kernel:\n",
      "Best parameters: {'C': 5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Best accuracy: 0.9293603541714373\n",
      "Overall accuracy: 0.961653054474213\n",
      "Results for S&P BSE Sensex:\n",
      "Polynomial Kernel:\n",
      "Best parameters: {'C': 100, 'degree': 1, 'kernel': 'poly'}\n",
      "Best accuracy: 0.9964962406015039\n",
      "Radial Basis Kernel:\n",
      "Best parameters: {'C': 5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Best accuracy: 0.9323947368421053\n",
      "Overall accuracy: 0.9644454887218046\n",
      "Results for TATA:\n",
      "Polynomial Kernel:\n",
      "Best parameters: {'C': 10, 'degree': 1, 'kernel': 'poly'}\n",
      "Best accuracy: 0.9914243187542935\n",
      "Radial Basis Kernel:\n",
      "Best parameters: {'C': 5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Best accuracy: 0.9313920056993105\n",
      "Overall accuracy: 0.961408162226802\n",
      "\n",
      "Accuracy:\n",
      "BHEL: 0.9571126885988346\n",
      "NIFTY BANK: 0.961653054474213\n",
      "S&P BSE Sensex: 0.9644454887218046\n",
      "TATA: 0.961408162226802\n",
      "\n",
      "Overall accuracy: 0.9611548485054136\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define dataset names\n",
    "dataset_names = [\"BHEL\", \"NIFTY BANK\", \"S&P BSE Sensex\", \"TATA\"]\n",
    "\n",
    "# Define the parameters grid for SVM\n",
    "param_grid_poly = {\n",
    "    'kernel': ['poly'],\n",
    "    'degree': [1, 2, 3, 4],\n",
    "    'C': [0.5, 1, 5, 10, 100]\n",
    "}\n",
    "\n",
    "param_grid_rbf = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 10.0],\n",
    "    'C': [0.5, 1, 5, 10]\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for idx, (dataset, dataset_name) in enumerate(zip(trend_data, dataset_names)):\n",
    "    numeric_columns = dataset.drop(['Close Price', 'Movement'], axis=1).select_dtypes(include=np.number).columns\n",
    "    X = dataset[numeric_columns]\n",
    "    y = dataset['Movement']\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_filled = imputer.fit_transform(X)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define the SVM model\n",
    "    svm_model = SVC()\n",
    "\n",
    "    # Perform grid search for polynomial kernel\n",
    "    grid_search_poly = GridSearchCV(estimator=svm_model, param_grid=param_grid_poly, cv=5, scoring='accuracy')\n",
    "    grid_search_poly.fit(X_train_scaled, y_train)\n",
    "    best_model_poly = grid_search_poly.best_estimator_\n",
    "    \n",
    "    # Perform grid search for radial basis kernel\n",
    "    grid_search_rbf = GridSearchCV(estimator=svm_model, param_grid=param_grid_rbf, cv=5, scoring='accuracy')\n",
    "    grid_search_rbf.fit(X_train_scaled, y_train)\n",
    "    best_model_rbf = grid_search_rbf.best_estimator_\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'dataset_name': dataset_name,\n",
    "        'best_model_poly': best_model_poly,\n",
    "        'best_params_poly': grid_search_poly.best_params_,\n",
    "        'accuracy_poly': grid_search_poly.best_score_,\n",
    "        'best_model_rbf': best_model_rbf,\n",
    "        'best_params_rbf': grid_search_rbf.best_params_,\n",
    "        'accuracy_rbf': grid_search_rbf.best_score_,\n",
    "    })\n",
    "\n",
    "# Store overall accuracies\n",
    "overall_accuracies = []\n",
    "\n",
    "# Print results for each dataset\n",
    "for result in results:\n",
    "    dataset_name = result['dataset_name']\n",
    "    \n",
    "    print(f\"Results for {dataset_name}:\")\n",
    "    print(\"Polynomial Kernel:\")\n",
    "    print(f\"Best parameters: {result['best_params_poly']}\")\n",
    "    print(f\"Best accuracy: {result['accuracy_poly']}\")\n",
    "    print(\"Radial Basis Kernel:\")\n",
    "    print(f\"Best parameters: {result['best_params_rbf']}\")\n",
    "    print(f\"Best accuracy: {result['accuracy_rbf']}\")\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = (result['accuracy_poly'] + result['accuracy_rbf']) / 2\n",
    "    print(f\"Overall accuracy: {overall_accuracy}\")\n",
    "    \n",
    "    # Append overall accuracy to the list\n",
    "    overall_accuracies.append(overall_accuracy)\n",
    "\n",
    "# Print overall accuracies\n",
    "print(\"\\nAccuracy:\")\n",
    "for result in results:\n",
    "    dataset_name = result['dataset_name']\n",
    "    overall_accuracy = (result['accuracy_poly'] + result['accuracy_rbf']) / 2\n",
    "    print(f\"{dataset_name}: {overall_accuracy}\")\n",
    "\n",
    "# Calculate the mean of overall accuracies\n",
    "ovacc_svm_cont = np.mean(overall_accuracies)\n",
    "\n",
    "# Print overall accuracy mean\n",
    "print(\"\\nOverall accuracy:\", ovacc_svm_cont)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5376369-74a6-41c6-b8bd-52e9ab4754ee",
   "metadata": {},
   "source": [
    "# Random Forest for continous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bad0ab3b-cae0-45f0-ab57-58b3462d7a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BHEL:\n",
      "Number of trees: 40, Accuracy: 0.9455645161290323\n",
      "Number of trees: 30, Accuracy: 0.9455645161290323\n",
      "Number of trees: 120, Accuracy: 0.9415322580645161\n",
      "Results for NIFTY BANK:\n",
      "Number of trees: 180, Accuracy: 0.905241935483871\n",
      "Number of trees: 130, Accuracy: 0.905241935483871\n",
      "Number of trees: 200, Accuracy: 0.9032258064516129\n",
      "Results for S&P BSE Sensex:\n",
      "Number of trees: 20, Accuracy: 0.936\n",
      "Number of trees: 30, Accuracy: 0.934\n",
      "Number of trees: 10, Accuracy: 0.932\n",
      "Results for TATA:\n",
      "Number of trees: 100, Accuracy: 0.9536290322580645\n",
      "Number of trees: 90, Accuracy: 0.9536290322580645\n",
      "Number of trees: 80, Accuracy: 0.9536290322580645\n",
      "\n",
      "Overall accuracy for Random Forest: 0.9341048387096773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of values for the number of trees\n",
    "ntrees_range = range(10, 201, 10)\n",
    "\n",
    "# Store results\n",
    "results_rf = []\n",
    "\n",
    "for idx, (dataset, dataset_name) in enumerate(zip(indicator_data, dataset_names)):\n",
    "    numeric_columns = dataset.drop(['Close Price', 'Movement'], axis=1).select_dtypes(include=np.number).columns\n",
    "    X = dataset[numeric_columns]\n",
    "    y = dataset['Movement']\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_filled = imputer.fit_transform(X)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    for ntrees in ntrees_range:\n",
    "        # Define the Random Forest model\n",
    "        rf_model = RandomForestClassifier(n_estimators=ntrees, random_state=42)\n",
    "\n",
    "        # Train the model\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Store accuracy and parameters\n",
    "        accuracies.append((accuracy, ntrees))\n",
    "\n",
    "    # Sort accuracies in descending order\n",
    "    accuracies.sort(reverse=True)\n",
    "\n",
    "    # Store the top 3 parameters and accuracies\n",
    "    top_params = accuracies[:3]\n",
    "\n",
    "    # Print results for the current dataset\n",
    "    print(f\"Results for {dataset_name}:\")\n",
    "    for acc, params in top_params:\n",
    "        print(f\"Number of trees: {params}, Accuracy: {acc}\")\n",
    "\n",
    "    # Store the results for the current dataset\n",
    "    results_rf.append({\n",
    "        'dataset_name': dataset_name,\n",
    "        'top_params': top_params\n",
    "    })\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy_rf = np.mean([acc for dataset_result in results_rf for acc, _ in dataset_result['top_params']])\n",
    "\n",
    "# Print overall accuracy\n",
    "print(\"\\nOverall accuracy for Random Forest:\", overall_accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907fcb87-bc04-44b9-a029-9714135ecd3f",
   "metadata": {},
   "source": [
    "# Random Forest for trend deterministic data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70f7a062-924f-4ef6-afda-5824dee47aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top three parameters for each dataset:\n",
      "\n",
      "Dataset: BHEL\n",
      "Parameters: {'n_estimators': 10}, Accuracy: 0.9625243624127533\n",
      "Parameters: {'n_estimators': 20}, Accuracy: 0.9740050973663607\n",
      "Parameters: {'n_estimators': 30}, Accuracy: 0.9792323965950924\n",
      "\n",
      "Dataset: NIFTY BANK\n",
      "Parameters: {'n_estimators': 10}, Accuracy: 0.9711815561959654\n",
      "Parameters: {'n_estimators': 20}, Accuracy: 0.9596375206143491\n",
      "Parameters: {'n_estimators': 30}, Accuracy: 0.9763488864086888\n",
      "\n",
      "Dataset: S&P BSE Sensex\n",
      "Parameters: {'n_estimators': 10}, Accuracy: 0.9541874744167007\n",
      "Parameters: {'n_estimators': 20}, Accuracy: 0.9839754400327466\n",
      "Parameters: {'n_estimators': 30}, Accuracy: 0.9839541547277937\n",
      "\n",
      "Dataset: TATA\n",
      "Parameters: {'n_estimators': 10}, Accuracy: 0.9901884026586263\n",
      "Parameters: {'n_estimators': 20}, Accuracy: 0.9671353134213989\n",
      "Parameters: {'n_estimators': 30}, Accuracy: 0.9913544668587896\n",
      "\n",
      "Accuracy for each dataset:\n",
      "BHEL: Accuracy = 0.9792323965950924\n",
      "NIFTY BANK: Accuracy = 0.9763488864086888\n",
      "S&P BSE Sensex: Accuracy = 0.9839754400327466\n",
      "TATA: Accuracy = 0.9913544668587896\n",
      "\n",
      "Overall accuracy for Random Forest model: 0.9827277974738294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': list(range(10, 201, 10))\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results_rf = []\n",
    "\n",
    "# Function to train Random Forest model\n",
    "def train_rf(X_train, y_train, params):\n",
    "    # Define the Random Forest model\n",
    "    rf_model = RandomForestClassifier(**params)\n",
    "\n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    return rf_model\n",
    "\n",
    "# Function to perform grid search and get top parameters\n",
    "def get_top_parameters(X_train, y_train):\n",
    "    # Perform grid search\n",
    "    grid_search_rf = GridSearchCV(estimator=RandomForestClassifier(max_depth=1), param_grid=param_grid_rf, cv=5, scoring='accuracy')\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the top three parameters and their mean test score\n",
    "    top_params = grid_search_rf.cv_results_['params'][:3]\n",
    "    top_scores = grid_search_rf.cv_results_['mean_test_score'][:3]\n",
    "    \n",
    "    return top_params, top_scores\n",
    "\n",
    "for idx, (dataset, dataset_name) in enumerate(zip(trend_data, dataset_names)):\n",
    "    numeric_columns = dataset.drop(['Close Price', 'Movement'], axis=1).select_dtypes(include=np.number).columns\n",
    "    X = dataset[numeric_columns]\n",
    "    y = dataset['Movement']\n",
    "    \n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_filled = imputer.fit_transform(X)\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, _, y_train, _ = train_test_split(X_filled, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Get top parameters\n",
    "    top_params, top_scores = get_top_parameters(X_train, y_train)\n",
    "    \n",
    "    # Store results\n",
    "    results_rf.append({\n",
    "        'dataset_name': dataset_name,\n",
    "        'top_params': top_params,\n",
    "        'top_scores': top_scores\n",
    "    })\n",
    "\n",
    "# Print top three parameters for each dataset\n",
    "print(\"\\nTop three parameters for each dataset:\")\n",
    "for result in results_rf:\n",
    "    print(f\"\\nDataset: {result['dataset_name']}\")\n",
    "    for params, score in zip(result['top_params'], result['top_scores']):\n",
    "        print(f\"Parameters: {params}, Accuracy: {score}\")\n",
    "\n",
    "# Calculate accuracy for each dataset\n",
    "dataset_accuracies = [np.max(result['top_scores']) for result in results_rf]\n",
    "\n",
    "# Print accuracy for each dataset\n",
    "print(\"\\nAccuracy for each dataset:\")\n",
    "for dataset_name, accuracy in zip(dataset_names, dataset_accuracies):\n",
    "    print(f\"{dataset_name}: Accuracy = {accuracy}\")\n",
    "\n",
    "# Calculate overall accuracy of the model\n",
    "overall_accuracy_rf = np.mean(dataset_accuracies)\n",
    "\n",
    "# Print overall accuracy\n",
    "print(\"\\nOverall accuracy for Random Forest model:\", overall_accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ea9b17-65b3-4c68-a815-c6590814ce93",
   "metadata": {},
   "source": [
    "# Naive bayes for continous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edd87b21-4f99-442f-bd03-be3aee184804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Naive Bayes:\n",
      "BHEL: Accuracy = 0.7560483870967742\n",
      "NIFTY BANK: Accuracy = 0.7056451612903226\n",
      "S&P BSE Sensex: Accuracy = 0.76\n",
      "TATA: Accuracy = 0.7056451612903226\n",
      "\n",
      "Overall accuracy for Naive Bayes model: 0.7318346774193548\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define dataset names\n",
    "dataset_names = [\"BHEL\", \"NIFTY BANK\", \"S&P BSE Sensex\", \"TATA\"]\n",
    "\n",
    "# Store results\n",
    "results_nb = []\n",
    "\n",
    "# Function to train Naive Bayes model\n",
    "def train_nb(X_train, y_train):\n",
    "    # Define the Naive Bayes model\n",
    "    nb_model = GaussianNB()\n",
    "\n",
    "    # Train the model\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    return nb_model\n",
    "\n",
    "# Loop over each dataset\n",
    "for idx, (dataset, dataset_name) in enumerate(zip(indicator_data, dataset_names)):\n",
    "    # Select numeric columns\n",
    "    numeric_columns = dataset.drop(['Close Price', 'Movement'], axis=1).select_dtypes(include=np.number).columns\n",
    "    X = dataset[numeric_columns]\n",
    "    y = dataset['Movement']\n",
    "\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_filled = imputer.fit_transform(X)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_filled)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train Naive Bayes model\n",
    "    nb_model = train_nb(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results_nb.append({\n",
    "        'dataset_name': dataset_name,\n",
    "        'accuracy': accuracy\n",
    "    })\n",
    "\n",
    "# Print accuracy for each dataset\n",
    "print(\"Accuracy for Naive Bayes:\")\n",
    "for result in results_nb:\n",
    "    print(f\"{result['dataset_name']}: Accuracy = {result['accuracy']}\")\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy_nb = sum(result['accuracy'] for result in results_nb) / len(results_nb)\n",
    "\n",
    "# Print overall accuracy\n",
    "print(\"\\nOverall accuracy for Naive Bayes model:\", overall_accuracy_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f19637-d111-40a4-a658-82bffe1a75b8",
   "metadata": {},
   "source": [
    "# Naive Bayes for trend deterministic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf296e1d-e251-4cf7-8131-cf24d834ef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Naive Bayes:\n",
      "BHEL: Accuracy = 0.9375\n",
      "NIFTY BANK: Accuracy = 0.9717741935483871\n",
      "S&P BSE Sensex: Accuracy = 0.968\n",
      "TATA: Accuracy = 0.9657258064516129\n",
      "\n",
      "Overall accuracy for Naive Bayes model: 0.96075\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define dataset names\n",
    "dataset_names = [\"BHEL\", \"NIFTY BANK\", \"S&P BSE Sensex\", \"TATA\"]\n",
    "\n",
    "# Store results\n",
    "results_nb = []\n",
    "\n",
    "# Function to train Naive Bayes model\n",
    "def train_nb(X_train, y_train):\n",
    "    # Define the Naive Bayes model\n",
    "    nb_model = GaussianNB()\n",
    "\n",
    "    # Train the model\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    return nb_model\n",
    "\n",
    "# Loop over each dataset\n",
    "for idx, (dataset, dataset_name) in enumerate(zip(trend_data, dataset_names)):\n",
    "    # Select numeric columns\n",
    "    numeric_columns = dataset.drop(['Close Price', 'Movement'], axis=1).select_dtypes(include=np.number).columns\n",
    "    X = dataset[numeric_columns]\n",
    "    y = dataset['Movement']\n",
    "\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_filled = imputer.fit_transform(X)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_filled)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train Naive Bayes model\n",
    "    nb_model = train_nb(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results_nb.append({\n",
    "        'dataset_name': dataset_name,\n",
    "        'accuracy': accuracy\n",
    "    })\n",
    "\n",
    "# Print accuracy for each dataset\n",
    "print(\"Accuracy for Naive Bayes:\")\n",
    "for result in results_nb:\n",
    "    print(f\"{result['dataset_name']}: Accuracy = {result['accuracy']}\")\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy_nb = sum(result['accuracy'] for result in results_nb) / len(results_nb)\n",
    "\n",
    "# Print overall accuracy\n",
    "print(\"\\nOverall accuracy for Naive Bayes model:\", overall_accuracy_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb54ca5-a25f-4ad3-8e2a-2fdf1888f97b",
   "metadata": {},
   "source": [
    "# ANN for continous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6a52126-c092-4bfe-8b1e-d4490d80cc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch 40: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 34: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 26: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 7ms/step\n",
      "24/24 [==============================] - 1s 7ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 6ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 3s 40ms/step\n",
      "24/24 [==============================] - 1s 7ms/step\n",
      "24/24 [==============================] - 1s 6ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Epoch 39: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 35: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 34: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 6ms/step\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 21: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Epoch 39: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 29: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch 40: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 32: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 35: early stopping\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 12ms/step\n",
      "24/24 [==============================] - 1s 16ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 7ms/step\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 33: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch 40: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Epoch 36: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 7ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 28: early stopping\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Epoch 36: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Epoch 39: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 35: early stopping\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 7ms/step\n",
      "24/24 [==============================] - 0s 8ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 7ms/step\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 24: early stopping\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Epoch 39: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 1s 38ms/step\n",
      "24/24 [==============================] - 0s 6ms/step\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 29: early stopping\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 6ms/step\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch 40: early stopping\n",
      "24/24 [==============================] - 1s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 34: early stopping\n",
      "24/24 [==============================] - 0s 6ms/step\n",
      "24/24 [==============================] - 0s 6ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 28: early stopping\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Epoch 36: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Epoch 39: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Epoch 36: early stopping\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "\n",
      "Top three best parameters for each dataset:\n",
      "Dataset: BHEL\n",
      "Rank 1: {'n_neurons': 40, 'epochs': 40, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.9583333333333334}\n",
      "Rank 2: {'n_neurons': 10, 'epochs': 40, 'lr': 0.01, 'momentum': 0.2, 'dropout_rate': 0.5, 'accuracy': 0.9543010752688172}\n",
      "Rank 3: {'n_neurons': 20, 'epochs': 40, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.9543010752688172}\n",
      "Dataset: NIFTY BANK\n",
      "Rank 1: {'n_neurons': 10, 'epochs': 30, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.9112903225806451}\n",
      "Rank 2: {'n_neurons': 20, 'epochs': 30, 'lr': 0.01, 'momentum': 0.2, 'dropout_rate': 0.5, 'accuracy': 0.9099462365591398}\n",
      "Rank 3: {'n_neurons': 10, 'epochs': 30, 'lr': 0.01, 'momentum': 0.1, 'dropout_rate': 0.5, 'accuracy': 0.9086021505376344}\n",
      "Dataset: S&P BSE Sensex\n",
      "Rank 1: {'n_neurons': 10, 'epochs': 20, 'lr': 0.01, 'momentum': 0.2, 'dropout_rate': 0.5, 'accuracy': 0.9173333333333333}\n",
      "Rank 2: {'n_neurons': 30, 'epochs': 40, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.9146666666666666}\n",
      "Rank 3: {'n_neurons': 10, 'epochs': 40, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.912}\n",
      "Dataset: TATA\n",
      "Rank 1: {'n_neurons': 30, 'epochs': 40, 'lr': 0.01, 'momentum': 0.2, 'dropout_rate': 0.5, 'accuracy': 0.9543010752688172}\n",
      "Rank 2: {'n_neurons': 30, 'epochs': 40, 'lr': 0.01, 'momentum': 0.1, 'dropout_rate': 0.5, 'accuracy': 0.9475806451612904}\n",
      "Rank 3: {'n_neurons': 10, 'epochs': 40, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.946236559139785}\n",
      "\n",
      "Accuracy of each dataset:\n",
      "Dataset: BHEL, Accuracy: 0.9583333333333334\n",
      "Dataset: NIFTY BANK, Accuracy: 0.9112903225806451\n",
      "Dataset: S&P BSE Sensex, Accuracy: 0.9173333333333333\n",
      "Dataset: TATA, Accuracy: 0.9543010752688172\n",
      "\n",
      "Overall Accuracy of the model: 0.9353145161290322\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define function to create ANN model\n",
    "def create_model(input_dim, n_neurons, lr, momentum, dropout_rate):\n",
    "    model = Sequential([\n",
    "        Dense(n_neurons, input_dim=input_dim, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    optimizer = SGD(lr=lr, momentum=momentum)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_neurons': [10, 20,30,40],  # Reduced number of neurons\n",
    "    'epochs': [10,20,30,40],      # Reduced number of epochs\n",
    "    'lr': [0.01],           # Lower learning rate\n",
    "    'momentum': [0.1,0.2,0.3],      # Lower momentum\n",
    "    'dropout_rate': [0.5]   # Higher dropout rate\n",
    "}\n",
    "\n",
    "# Initialize variables\n",
    "dataset_names = [\"BHEL\", \"NIFTY BANK\", \"S&P BSE Sensex\", \"TATA\"]\n",
    "best_params_per_dataset = {}\n",
    "dataset_accuracies = {}\n",
    "overall_accuracies = []\n",
    "\n",
    "# Iterate over datasets\n",
    "for idx, dataset in enumerate(indicator_data):\n",
    "    numeric_columns = dataset.drop(['Close Price', 'Movement'], axis=1).select_dtypes(include=np.number).columns\n",
    "    X = dataset[numeric_columns]\n",
    "    y = dataset['Movement']\n",
    "    \n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_filled = imputer.fit_transform(X)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_filled)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Initialize variables for this dataset\n",
    "    dataset_accuracy = 0\n",
    "    top_three_params = [{'accuracy': 0.0}, {'accuracy': 0.0}, {'accuracy': 0.0}]\n",
    "\n",
    "    # Iterate over parameter grid\n",
    "    for n_neurons, epochs, lr, momentum, dropout_rate in product(param_grid['n_neurons'], param_grid['epochs'], param_grid['lr'], param_grid['momentum'], param_grid['dropout_rate']):\n",
    "        # Create and compile model\n",
    "        model = create_model(X_train.shape[1], n_neurons, lr, momentum, dropout_rate)\n",
    "\n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='loss', verbose=1, patience=3, restore_best_weights=True)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train, epochs=epochs, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "        # Evaluate model\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Update dataset accuracy\n",
    "        dataset_accuracy = max(dataset_accuracy, accuracy)\n",
    "\n",
    "        # Update top three parameters\n",
    "        for i, params in enumerate(top_three_params):\n",
    "            if accuracy > params['accuracy']:\n",
    "                for j in range(2, i, -1):\n",
    "                    top_three_params[j] = top_three_params[j - 1]\n",
    "                top_three_params[i] = {'n_neurons': n_neurons, 'epochs': epochs, 'lr': lr, 'momentum': momentum, 'dropout_rate': dropout_rate, 'accuracy': accuracy}\n",
    "                break\n",
    "\n",
    "    # Save top three best parameters for this dataset\n",
    "    best_params_per_dataset[dataset_names[idx]] = top_three_params\n",
    "\n",
    "    # Store dataset accuracy\n",
    "    dataset_accuracies[dataset_names[idx]] = dataset_accuracy\n",
    "    overall_accuracies.append(dataset_accuracy)\n",
    "\n",
    "# Calculate overall accuracy of the model\n",
    "overall_accuracy = np.mean(overall_accuracies)\n",
    "\n",
    "# Print top three best parameters for each dataset\n",
    "print(\"\\nTop three best parameters for each dataset:\")\n",
    "for dataset, params in best_params_per_dataset.items():\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for i, param in enumerate(params, start=1):\n",
    "        print(f\"Rank {i}: {param}\")\n",
    "\n",
    "# Print accuracy of each dataset\n",
    "print(\"\\nAccuracy of each dataset:\")\n",
    "for dataset, accuracy in dataset_accuracies.items():\n",
    "    print(f\"Dataset: {dataset}, Accuracy: {accuracy}\")\n",
    "\n",
    "# Print overall accuracy of the model\n",
    "print(f\"\\nOverall Accuracy of the model: {overall_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06049eb0-13e2-41c6-b7f9-7697b3a3f1c9",
   "metadata": {},
   "source": [
    "# ANN for trend deterministic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25b2dcd7-d76e-4d8f-a58c-144213a9ae13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 26: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Epoch 27: early stopping\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 33: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Epoch 37: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 8ms/step\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Epoch 22: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Epoch 18: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Epoch 22: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Epoch 37: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 20: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 24: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 23: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 26: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Epoch 37: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 35: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Epoch 27: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 28: early stopping\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 28: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 33: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 30: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 26: early stopping\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 38: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 24: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 26: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 20: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 23: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 30: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 30: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 17: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 30: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 33: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 30: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 1s 14ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 29: early stopping\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 28: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch 40: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 7ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 6ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 33: early stopping\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 25: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 38: early stopping\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 38: early stopping\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Epoch 37: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 1s 5ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 38: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 17: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 6ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 30: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 38: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 33: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 20: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 30: early stopping\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch 40: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 32: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 1s 12ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 23: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 23: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 28: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 28: early stopping\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Epoch 36: early stopping\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 17: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 25: early stopping\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 29: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 38: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Epoch 27: early stopping\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 33: early stopping\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "\n",
      "Top three best parameters for each dataset:\n",
      "Dataset: BHEL\n",
      "Rank 1: {'n_neurons': 20, 'epochs': 40, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.9825268817204301}\n",
      "Rank 2: {'n_neurons': 10, 'epochs': 40, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.9798387096774194}\n",
      "Rank 3: {'n_neurons': 10, 'epochs': 40, 'lr': 0.01, 'momentum': 0.2, 'dropout_rate': 0.5, 'accuracy': 0.978494623655914}\n",
      "Dataset: NIFTY BANK\n",
      "Rank 1: {'n_neurons': 30, 'epochs': 30, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.9865591397849462}\n",
      "Rank 2: {'n_neurons': 40, 'epochs': 40, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.9852150537634409}\n",
      "Rank 3: {'n_neurons': 30, 'epochs': 30, 'lr': 0.01, 'momentum': 0.1, 'dropout_rate': 0.5, 'accuracy': 0.9838709677419355}\n",
      "Dataset: S&P BSE Sensex\n",
      "Rank 1: {'n_neurons': 20, 'epochs': 30, 'lr': 0.01, 'momentum': 0.1, 'dropout_rate': 0.5, 'accuracy': 0.9826666666666667}\n",
      "Rank 2: {'n_neurons': 40, 'epochs': 40, 'lr': 0.01, 'momentum': 0.2, 'dropout_rate': 0.5, 'accuracy': 0.9826666666666667}\n",
      "Rank 3: {'n_neurons': 40, 'epochs': 30, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.9813333333333333}\n",
      "Dataset: TATA\n",
      "Rank 1: {'n_neurons': 40, 'epochs': 40, 'lr': 0.01, 'momentum': 0.2, 'dropout_rate': 0.5, 'accuracy': 0.9852150537634409}\n",
      "Rank 2: {'n_neurons': 30, 'epochs': 40, 'lr': 0.01, 'momentum': 0.3, 'dropout_rate': 0.5, 'accuracy': 0.9838709677419355}\n",
      "Rank 3: {'n_neurons': 40, 'epochs': 40, 'lr': 0.01, 'momentum': 0.1, 'dropout_rate': 0.5, 'accuracy': 0.9838709677419355}\n",
      "\n",
      "Accuracy of each dataset:\n",
      "Dataset: BHEL, Accuracy: 0.9825268817204301\n",
      "Dataset: NIFTY BANK, Accuracy: 0.9865591397849462\n",
      "Dataset: S&P BSE Sensex, Accuracy: 0.9826666666666667\n",
      "Dataset: TATA, Accuracy: 0.9852150537634409\n",
      "\n",
      "Overall Accuracy of the model: 0.9842419354838711\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define function to create ANN model\n",
    "def create_model(input_dim, n_neurons, lr, momentum, dropout_rate):\n",
    "    model = Sequential([\n",
    "        Dense(n_neurons, input_dim=input_dim, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    optimizer = SGD(lr=lr, momentum=momentum)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_neurons': [10, 20,30,40],  # Reduced number of neurons\n",
    "    'epochs': [10,20,30,40],      # Reduced number of epochs\n",
    "    'lr': [0.01],           # Lower learning rate\n",
    "    'momentum': [0.1,0.2,0.3],      # Lower momentum\n",
    "    'dropout_rate': [0.5]   # Higher dropout rate\n",
    "}\n",
    "\n",
    "# Initialize variables\n",
    "dataset_names = [\"BHEL\", \"NIFTY BANK\", \"S&P BSE Sensex\", \"TATA\"]\n",
    "best_params_per_dataset = {}\n",
    "dataset_accuracies = {}\n",
    "overall_accuracies = []\n",
    "\n",
    "# Iterate over datasets\n",
    "for idx, dataset in enumerate(trend_data):\n",
    "    numeric_columns = dataset.drop(['Close Price', 'Movement'], axis=1).select_dtypes(include=np.number).columns\n",
    "    X = dataset[numeric_columns]\n",
    "    y = dataset['Movement']\n",
    "    \n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_filled = imputer.fit_transform(X)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_filled)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Initialize variables for this dataset\n",
    "    dataset_accuracy = 0\n",
    "    top_three_params = [{'accuracy': 0.0}, {'accuracy': 0.0}, {'accuracy': 0.0}]\n",
    "\n",
    "    # Iterate over parameter grid\n",
    "    for n_neurons, epochs, lr, momentum, dropout_rate in product(param_grid['n_neurons'], param_grid['epochs'], param_grid['lr'], param_grid['momentum'], param_grid['dropout_rate']):\n",
    "        # Create and compile model\n",
    "        model = create_model(X_train.shape[1], n_neurons, lr, momentum, dropout_rate)\n",
    "\n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='loss', verbose=1, patience=3, restore_best_weights=True)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train, epochs=epochs, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "        # Evaluate model\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Update dataset accuracy\n",
    "        dataset_accuracy = max(dataset_accuracy, accuracy)\n",
    "\n",
    "        # Update top three parameters\n",
    "        for i, params in enumerate(top_three_params):\n",
    "            if accuracy > params['accuracy']:\n",
    "                for j in range(2, i, -1):\n",
    "                    top_three_params[j] = top_three_params[j - 1]\n",
    "                top_three_params[i] = {'n_neurons': n_neurons, 'epochs': epochs, 'lr': lr, 'momentum': momentum, 'dropout_rate': dropout_rate, 'accuracy': accuracy}\n",
    "                break\n",
    "\n",
    "    # Save top three best parameters for this dataset\n",
    "    best_params_per_dataset[dataset_names[idx]] = top_three_params\n",
    "\n",
    "    # Store dataset accuracy\n",
    "    dataset_accuracies[dataset_names[idx]] = dataset_accuracy\n",
    "    overall_accuracies.append(dataset_accuracy)\n",
    "\n",
    "# Calculate overall accuracy of the model\n",
    "overall_accuracy = np.mean(overall_accuracies)\n",
    "\n",
    "# Print top three best parameters for each dataset\n",
    "print(\"\\nTop three best parameters for each dataset:\")\n",
    "for dataset, params in best_params_per_dataset.items():\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for i, param in enumerate(params, start=1):\n",
    "        print(f\"Rank {i}: {param}\")\n",
    "\n",
    "# Print accuracy of each dataset\n",
    "print(\"\\nAccuracy of each dataset:\")\n",
    "for dataset, accuracy in dataset_accuracies.items():\n",
    "    print(f\"Dataset: {dataset}, Accuracy: {accuracy}\")\n",
    "\n",
    "# Print overall accuracy of the model\n",
    "print(f\"\\nOverall Accuracy of the model: {overall_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fa4394c9-4aee-45ee-bebc-abd1aa3a9641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Overall accuracies for each model\n",
    "overall_accuracies = [0.9353145161290322, 0.9254535277205302, 0.9341048387096773, 0.7318346774193548]\n",
    "\n",
    "# Model names\n",
    "model_names = ['ANN','SVM','Random Forest', 'Naive Bayes']\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(model_names, overall_accuracies, color=['blue', 'green', 'red', 'orange'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.title('Overall Accuracy of all Models for Continuous Data')\n",
    "plt.ylim(0, 1)  # Set y-axis limit from 0 to 1 for better visualization\n",
    "#plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7095cba9-2f0f-4ae4-bf09-1d737b90dd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Overall accuracies for each model\n",
    "overall_accuracies = [overall_accuracy, ovacc_svm_cont, overall_accuracy_rf, 0.96075]\n",
    "\n",
    "# Model names\n",
    "model_names = ['ANN','SVM','Random Forest', 'Naive Bayes']\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(model_names, overall_accuracies, color=['blue', 'green', 'red', 'orange'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.title('Overall Accuracy of all Models for trend deterministic Data')\n",
    "plt.ylim(0, 1)  # Set y-axis limit from 0 to 1 for better visualization\n",
    "#plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
